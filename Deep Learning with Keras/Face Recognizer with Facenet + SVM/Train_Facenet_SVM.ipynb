{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "import cv2\n",
    "from PIL import Image\n",
    "#from mtcnn import MTCNN\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "from random import choice\n",
    "#import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load face detector model \n",
    "detector= cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load samples\n",
    "path1 = list(paths.list_images(os.path.join(os.getcwd(), 'jeska2')))\n",
    "path2 = list(paths.list_images(os.path.join(os.getcwd(), 'hue2')))\n",
    "path3 = list(paths.list_images(os.path.join(os.getcwd(), 'mina2')))\n",
    "path4 = list(paths.list_images(os.path.join(os.getcwd(), 'chu2')))\n",
    "path5 = list(paths.list_images(os.path.join(os.getcwd(), 'nga2')))\n",
    "path6 = list(paths.list_images(os.path.join(os.getcwd(), 'kha2')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [path1, path2, path3, path4, path5, path6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469\n",
      "[80, 74, 85, 79, 79, 72]\n"
     ]
    }
   ],
   "source": [
    "# preprocess images\n",
    "face_samples = []\n",
    "fs_len = []\n",
    "\n",
    "for path in paths:\n",
    "    length = 0\n",
    "    for i in range(len(path)):\n",
    "        # load the image and converting it to gray scale\n",
    "        pilImage = Image.open(path[i]).rotate(-90)\n",
    "        # convert the PIL image into numpy array\n",
    "        imageNp = np.array(pilImage, 'uint8')\n",
    "        # extract the face from the training image sample\n",
    "        faces = detector.detectMultiScale(imageNp, scaleFactor=1.5, minNeighbors=5)\n",
    "        # resize faces to 160x160, covert them to array and append them to the list\n",
    "        for (x,y,w,h) in faces:\n",
    "            face = imageNp[y:y+h,x:x+w]\n",
    "            image = Image.fromarray(face)\n",
    "            image = image.resize((160,160))\n",
    "            face_array = np.asarray(image)\n",
    "            face_samples.append(face_array)\n",
    "            length += 1\n",
    "\n",
    "    fs_len.append(length)\n",
    "    \n",
    "print(len(face_samples))\n",
    "print(fs_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(469, 1)\n"
     ]
    }
   ],
   "source": [
    "# labels vector\n",
    "labels = np.concatenate((np.zeros((80, 1)), np.ones((74, 1)), np.ones((85, 1))*2, np.ones((79, 1))*3, np.ones((79, 1))*4, np.ones((72, 1))*5), axis = 0)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# load Facenet model\n",
    "facenet = load_model('facenet_keras.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Facenet model to create embedding vector to each sample\n",
    "\n",
    "embeddings = []\n",
    "\n",
    "for fs in face_samples:\n",
    "    fs = fs.astype('float32')\n",
    "    mean, std = fs.mean(), fs.std()\n",
    "    fs = (fs - mean) / std\n",
    "    sample = np.expand_dims(fs, axis = 0)\n",
    "    embedding = facenet.predict(sample)\n",
    "    embeddings.append(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.asarray(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embeddings.reshape(469, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\My Laptop\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use Support Vector Machine algorithsm to classify the embedding vectors with corresponding labels\n",
    "model = SVC(kernel = 'linear')\n",
    "model.fit(embeddings, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['facenet_svm.joblib']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model\n",
    "dump(model, 'facenet_svm.joblib') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
