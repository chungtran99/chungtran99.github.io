{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(2)\n",
    "\n",
    "# Generate random samples that satisfy a linear regression\n",
    "X = np.random.rand(1000, 1)\n",
    "y = 4 + 3 * X + .2*np.random.randn(1000, 1)\n",
    "\n",
    "# Building Xbar \n",
    "one = np.ones((X.shape[0],1))\n",
    "Xbar = np.concatenate((one, X), axis = 1)\n",
    "\n",
    "# Find weight using formular\n",
    "A = np.dot(Xbar.T, Xbar)\n",
    "b = np.dot(Xbar.T, y)\n",
    "w_exact = np.dot(np.linalg.pinv(A), b)\n",
    "\n",
    "# Cost function \n",
    "def cost(w):\n",
    "    return .5/Xbar.shape[0]*np.linalg.norm(y - Xbar.dot(w), 2)**2\n",
    "\n",
    "# Gradient\n",
    "def grad(w):\n",
    "    return 1/Xbar.shape[0] * Xbar.T.dot(Xbar.dot(w) - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single point gradient\n",
    "def sgrad(w, i, rd_id):\n",
    "    true_i = rd_id[i]\n",
    "    xi = Xbar[true_i, :]\n",
    "    yi = y[true_i]\n",
    "    a = np.dot(xi, w) - yi\n",
    "    return (xi*a).reshape(2, 1)\n",
    "\n",
    "# Stochastic Gradient Descent\n",
    "def SGD(w_init, grad, eta):\n",
    "    w = [w_init]\n",
    "    w_last_check = w_init\n",
    "    iter_check_w = 10\n",
    "    N = X.shape[0]\n",
    "    count = 0\n",
    "    for it in range(10):\n",
    "        # shuffle data \n",
    "        rd_id = np.random.permutation(N)\n",
    "        for i in range(N):\n",
    "            count += 1 \n",
    "            g = sgrad(w[-1], i, rd_id)\n",
    "            w_new = w[-1] - eta*g\n",
    "            w.append(w_new)\n",
    "            w_this_check = w_new\n",
    "            if np.linalg.norm(sgrad(w_this_check, i, rd_id)-sgrad(w_last_check, i, rd_id))/len(w_init) < 1e-3:                                    \n",
    "                return w, count\n",
    "            \n",
    "            if count%iter_check_w == 0:\n",
    "                w_last_check = w_this_check\n",
    "                 \n",
    "            \n",
    "    return w, count\n",
    "\n",
    "w_init = np.array([[2], [1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nN = X.shape[0]\\na1 = np.linalg.norm(y, 2)**2/N\\nb1 = 2*np.sum(X)/N\\nc1 = np.linalg.norm(X, 2)**2/N\\nd1 = -2*np.sum(y)/N \\ne1 = -2*X.T.dot(y)/N\\n\\nmatplotlib.rcParams['xtick.direction'] = 'out'\\nmatplotlib.rcParams['ytick.direction'] = 'out'\\n\\ndelta = 0.025\\nxg = np.arange(1.5, 7.0, delta)\\nyg = np.arange(0.5, 4.5, delta)\\nXg, Yg = np.meshgrid(xg, yg)\\n\\nZ = a1 + Xg**2 +b1*Xg*Yg + c1*Yg**2 + d1*Xg + e1*Yg\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "N = X.shape[0]\n",
    "a1 = np.linalg.norm(y, 2)**2/N\n",
    "b1 = 2*np.sum(X)/N\n",
    "c1 = np.linalg.norm(X, 2)**2/N\n",
    "d1 = -2*np.sum(y)/N \n",
    "e1 = -2*X.T.dot(y)/N\n",
    "\n",
    "matplotlib.rcParams['xtick.direction'] = 'out'\n",
    "matplotlib.rcParams['ytick.direction'] = 'out'\n",
    "\n",
    "delta = 0.025\n",
    "xg = np.arange(1.5, 7.0, delta)\n",
    "yg = np.arange(0.5, 4.5, delta)\n",
    "Xg, Yg = np.meshgrid(xg, yg)\n",
    "\n",
    "Z = a1 + Xg**2 +b1*Xg*Yg + c1*Yg**2 + d1*Xg + e1*Yg\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport matplotlib.animation as animation\\nfrom matplotlib.animation import FuncAnimation\\ndef save_gif2(eta):\\n    w, it = SGD(w_init, grad, eta)\\n    fig, ax = plt.subplots(figsize=(10,10))    \\n    plt.cla()\\n    plt.axis([1.5, 7, 0.5, 4.5])\\n\\n    def update(ii):\\n        if ii == 0:\\n            plt.cla()\\n            CS = plt.contour(Xg, Yg, Z, 100)\\n            manual_locations = [(4.5, 3.5), (4.2, 3), (4.3, 3.3)]\\n            animlist = plt.clabel(CS, inline=.1, fontsize=10, manual=manual_locations)\\n            plt.plot(w_exact[0], w_exact[1], 'go')\\n        else:\\n            animlist = plt.plot([w[ii-1][0], w[ii][0]], [w[ii-1][1], w[ii][1]], 'r-')\\n            animlist = plt.plot(w[ii][0], w[ii][1], 'ro', markersize = 4) \\n            xlabel = '$\\\\eta =$ ' + str(eta) + '; iter = %d/%d' %(ii, it)\\n            xlabel += '; ||grad||_2 = %.3f' % np.linalg.norm(grad(w[ii]))\\n            ax.set_xlabel(xlabel)\\n        return animlist, ax\\n       \\n    anim1 = FuncAnimation(fig, update, frames=np.arange(0, it), interval=50)\\n    fn = 'Stochastic Gradient Descent_contours.gif'\\n    anim1.save(fn, dpi=100, writer='imagemagick')\\n    \\neta = 1 \\nsave_gif2(eta)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.animation import FuncAnimation\n",
    "def save_gif2(eta):\n",
    "    w, it = SGD(w_init, grad, eta)\n",
    "    fig, ax = plt.subplots(figsize=(10,10))    \n",
    "    plt.cla()\n",
    "    plt.axis([1.5, 7, 0.5, 4.5])\n",
    "\n",
    "    def update(ii):\n",
    "        if ii == 0:\n",
    "            plt.cla()\n",
    "            CS = plt.contour(Xg, Yg, Z, 100)\n",
    "            manual_locations = [(4.5, 3.5), (4.2, 3), (4.3, 3.3)]\n",
    "            animlist = plt.clabel(CS, inline=.1, fontsize=10, manual=manual_locations)\n",
    "            plt.plot(w_exact[0], w_exact[1], 'go')\n",
    "        else:\n",
    "            animlist = plt.plot([w[ii-1][0], w[ii][0]], [w[ii-1][1], w[ii][1]], 'r-')\n",
    "            animlist = plt.plot(w[ii][0], w[ii][1], 'ro', markersize = 4) \n",
    "            xlabel = '$\\eta =$ ' + str(eta) + '; iter = %d/%d' %(ii, it)\n",
    "            xlabel += '; ||grad||_2 = %.3f' % np.linalg.norm(grad(w[ii]))\n",
    "            ax.set_xlabel(xlabel)\n",
    "        return animlist, ax\n",
    "       \n",
    "    anim1 = FuncAnimation(fig, update, frames=np.arange(0, it), interval=50)\n",
    "    fn = 'Stochastic Gradient Descent_contours.gif'\n",
    "    anim1.save(fn, dpi=100, writer='imagemagick')\n",
    "    \n",
    "eta = 1 \n",
    "save_gif2(eta)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
